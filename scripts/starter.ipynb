{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "684c25ac-112a-43da-892f-de71c4ed37b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Guided Initialization: Databricks Assessment Utility\n",
    "## Overview\n",
    "This notebook streamlines the process of installing necessary dependencies and launching the Databricks assessment utility, offering a consistent approach for both Serverless and cluster-based compute environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d8bc3f6-4333-4e83-a1d1-367b318c600a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "print(f\"Current working directory: {current_working_directory}\")\n",
    "\n",
    "# Construct the path(s)\n",
    "requirements_file_path = os.path.join(current_working_directory, \"..\", \"requirements.txt\")\n",
    "script_path = os.path.join(current_working_directory, \"databricks_assessment.py\")\n",
    "\n",
    "# Print the constructed path\n",
    "print(f\"Path to requirements.txt: {requirements_file_path}\")\n",
    "print(f\"Path to databricks_assessment.py: {script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2d34d88-2c87-4c46-9ff1-166c98f807e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Install dependencies\n",
    "- Installs dependencies defined in **`requirements.txt`** using **`%pip install -r`** magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea71ab34-d292-42cb-8f24-9905d0ba4783",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %pip install -r $requirements_file_path\n",
    "    print(\"Successfully installed dependencies from requirements.txt\")\n",
    "except Exception as e:\n",
    "    print(f\"Error installing dependencies: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a67d9d03-cd0b-4397-8071-f150bb24a21e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Restart the python process attached to the notebook\n",
    "- Restart the Python process attached to the notebook for the newly installed libraries to be available in the current session\n",
    "- Refer https://docs.databricks.com/aws/en/libraries/restart-python-process\n",
    "\"\"\"\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resetting paths after notebook restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_working_directory = os.getcwd()\n",
    "print(f\"Current working directory: {current_working_directory}\")\n",
    "\n",
    "# Construct the path(s)\n",
    "requirements_file_path = os.path.join(current_working_directory, \"..\", \"requirements.txt\")\n",
    "script_path = os.path.join(current_working_directory, \"databricks_assessment.py\")\n",
    "\n",
    "# Print the constructed path\n",
    "print(f\"Path to requirements.txt: {requirements_file_path}\")\n",
    "print(f\"Path to databricks_assessment.py: {script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d345896-0335-4c5f-9ddd-66bf00834d53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Verifying Installed Dependencies\n",
    "- Programmatically check if the dependencies listed in your **`requirements.txt`** file were installed accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae0efe53-febe-43c6-b048-8afc5c10af71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "\n",
    "def get_installed_package_info(package_name):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"pip\", \"show\", package_name],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        output = result.stdout\n",
    "        version_match = re.search(r\"Version: (\\S+)\", output)\n",
    "        if version_match:\n",
    "            version = version_match.group(1)\n",
    "            return package_name, version\n",
    "        else:\n",
    "            return package_name, \"Version information not found\"\n",
    "    except subprocess.CalledProcessError:\n",
    "        return package_name, \"Not installed\"\n",
    "    except FileNotFoundError:\n",
    "        return package_name, \"pip command not found\"\n",
    "\n",
    "def print_installed_versions_from_requirements(requirements_file):\n",
    "    try:\n",
    "        with open(requirements_file, \"r\") as f:\n",
    "            package_number = 1\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith(\"#\"):\n",
    "                    package_name = line.split(\"==\")[0].split(\">=\")[0].split(\"<=\")[0].split(\"!=\")[0].split(\">\")[0].split(\"<\")[0].split(\"~=\")[0]\n",
    "                    name, version = get_installed_package_info(package_name)\n",
    "                    print(f\"Package {package_number} => {name}: {version}\")\n",
    "                    package_number += 1\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {requirements_file} not found.\")\n",
    "\n",
    "print_installed_versions_from_requirements(requirements_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f25c9a58-78a5-4d32-b5ca-8cb7a5890f05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Execute Databricks Assessment Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d123469b-df9f-485a-af0b-e7f0c496ef49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db3c61be-9e11-4a29-bb1c-0b789033e27c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_assessment import DatabricksAssessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "077cb62e-5f63-41df-99d2-3b0333a646d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_customer_name = \"dbx_demo_customer    \" # Set this to your customer name\n",
    "\n",
    "assessor = DatabricksAssessment(customer_name=input_customer_name)\n",
    "assessor.process_workspace_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5103a4ff-33ce-48c7-ae98-509bed69df50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Transfer output files from Databricks workspace to S3\n",
    "> - Provide a valid [Unity Catalog Volume](https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-volumes) location to the **`input_value`** parameter. \n",
    ">   - Format: _**`/Volumes/mycatalog/myschema/myexternalvolume`**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb61df48-e2f2-4166-a25d-4eef9772cfaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_value = \"/Volumes/dbx_demo/default/demo_volume\" # Enter your input value here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed6eec40-02b6-400f-8f55-e38f8a8ce0c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "helper_notebook_path = \"./databricks_cloud_storage_writer\" # Notebook path (Do not change, unless you have moved the notebook)\n",
    "timeout = 300\n",
    "\n",
    "args_to_pass = {\"target_volume_location\": input_value}\n",
    "\n",
    "try:\n",
    "    processed_result = dbutils.notebook.run(helper_notebook_path, timeout, args_to_pass)\n",
    "except Exception as e:\n",
    "    print(f\"Error running {helper_notebook_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d8645ea-d5ab-4992-bda1-3a7044ef0326",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ======== END ========"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fb240a7-b4a1-4664-a273-0f2208d6a733",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Additional helpers _(not required for tool execution)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5340a0ff-e059-4f68-9d62-651fc9e572e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Execute the Python script using the `%run` magic command\n",
    "\"\"\"\n",
    "# %run $script_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffdeb226-d993-41e2-9a0e-9fdc5a67cd4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "pandas>2.0",
     "-r /Workspace/Shared/Shared_Workspace_Folder/Discovery_code/databricks-discovery-tool/pso-databricks-discovery-tool/requirements.txt"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "starter",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
